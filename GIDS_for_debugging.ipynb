{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed: 999\n"
     ]
    },
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x2cee89adc50>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set a manual seed to prevent different result while every running\n",
    "\n",
    "manualSeed = 999\n",
    "print(\"Random seed:\", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "data_root = \"./CAN_image_dataset/\"    # dataset root\n",
    "workers = 2                 # using thread numbers\n",
    "batch_size = 128            # batch_size\n",
    "nc = 1                      # number of channel from input images\n",
    "num_epochs = 20             # number of training epochs\n",
    "lr = 0.0002                 # learning rate\n",
    "beta1 = 0.5                 # hyperparameter for adam optimizer\n",
    "ngpu = 1                    # number of available gpu"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "dataset = dset.ImageFolder(root=data_root)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size = batch_size,shuffle=True,num_workers=workers)\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# v1 : except nn.BatchNorm2d(channel size)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # Input : N x channel noise x 1 x 1\n",
    "            nn.ConvTranspose2d(256,512,(3,4),stride=1,padding=0,bias=False),\n",
    "            nn.ReLU(True),\n",
    "            # second layer\n",
    "            nn.ConvTranspose2d(512,256,(3,4),stride=4,padding=0,bias=False),\n",
    "            nn.ReLU(True),\n",
    "            # third layer\n",
    "            nn.ConvTranspose2d(256,128,(3,4),stride=4,padding=0,bias=False),\n",
    "            nn.ReLU(True),\n",
    "            # fourth layer\n",
    "            nn.ConvTranspose2d(128,64,(3,4),stride=4,padding=0,bias=False),\n",
    "            nn.ReLU(True),\n",
    "            # Final layer\n",
    "            nn.ConvTranspose2d(64,1,(3,4),stride=4,padding=0,bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self,input):\n",
    "        return self.main(input)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (main): Sequential(\n",
      "    (0): ConvTranspose2d(256, 512, kernel_size=(3, 4), stride=(1, 1), bias=False)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): ConvTranspose2d(512, 256, kernel_size=(3, 4), stride=(4, 4), bias=False)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): ConvTranspose2d(256, 128, kernel_size=(3, 4), stride=(4, 4), bias=False)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): ConvTranspose2d(128, 64, kernel_size=(3, 4), stride=(4, 4), bias=False)\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): ConvTranspose2d(64, 1, kernel_size=(3, 4), stride=(4, 4), bias=False)\n",
      "    (9): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "netG = Generator(ngpu).to(device)\n",
    "\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    netG = nn.DataParallel(netG,list(range(ngpu)))\n",
    "\n",
    "netG.apply(weights_init)\n",
    "\n",
    "print(netG)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(nc,1,(3,4),stride=1, padding=0, bias=False),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(1,1,(3,4),stride=1,padding=0,bias=False),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(1,1,(3,4),stride=1,padding=0,bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d(1, 1, kernel_size=(3, 4), stride=(1, 1), bias=False)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(1, 1, kernel_size=(3, 4), stride=(1, 1), bias=False)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Conv2d(1, 1, kernel_size=(3, 4), stride=(1, 1), bias=False)\n",
      "    (5): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "netD = Discriminator(ngpu).to(device)\n",
    "\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    netD = nn.DataParallel(netD,list(range(ngpu)))\n",
    "\n",
    "netD.apply(weights_init)\n",
    "\n",
    "print(netD)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "\n",
    "fixed_noise = torch.randn(64,1,1,1,device=device)\n",
    "\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "optimizerD = optim.Adam(netD.parameters(), lr = lr, betas = (beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr = lr, betas = (beta1, 0.999))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# train process\n",
    "\n",
    "# save losses to check training state\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iter = 0\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "\n",
    "# iterate epoch\n",
    "for epoch in range(num_epochs):\n",
    "    # iterate batch in an epoch\n",
    "    for i ,data in enumerate(dataloader,0):\n",
    "        ####################\n",
    "        # (1) update discriminator network : maximize log(D(x)) + log(1 - D(G(z))))\n",
    "        ####################\n",
    "        # @@train real data@@\n",
    "        netD.zero_grad()\n",
    "        # Adapt to the size of the batches or the device to be used\n",
    "        real_cpu = data[0].to(device)\n",
    "        b_size = real_cpu.size(0)\n",
    "        label = torch.full((b_size,), real_label,\n",
    "                           dtype=torch.float, device= device)\n",
    "        # pass batch composed real data to D\n",
    "        output = netD(real_cpu).view(-1)\n",
    "        # get losses\n",
    "        errD_real = criterion(output,label)\n",
    "        # calculate degree of change while doing backpropagation\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        # @@ train fake data @@\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}