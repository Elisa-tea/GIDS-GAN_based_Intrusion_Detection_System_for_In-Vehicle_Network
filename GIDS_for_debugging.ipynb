{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed: 999\n"
     ]
    },
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x293e1028a50>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set a manual seed to prevent different result while every running\n",
    "\n",
    "manualSeed = 999\n",
    "print(\"Random seed:\", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "data_root = \"./CAN_image_dataset/\"    # dataset root\n",
    "workers = 2                 # using thread numbers\n",
    "batch_size = 128            # batch_size\n",
    "nc = 1                      # number of channel from input images\n",
    "num_epochs = 20             # number of training epochs\n",
    "lr = 0.0002                 # learning rate\n",
    "beta1 = 0.5                 # hyperparameter for adam optimizer\n",
    "ngpu = 1                    # number of available gpu"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "dataset = dset.ImageFolder(root=data_root)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size = batch_size,shuffle=True,num_workers=workers)\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# v1 : except nn.BatchNorm2d(channel size)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # Input : N x channel noise x 1 x 1\n",
    "            nn.ConvTranspose2d(256,512,(3,4),stride=1,bias=False),\n",
    "            nn.ReLU(True),\n",
    "            # second layer\n",
    "            nn.ConvTranspose2d(512,256,4,stride=2,padding=1,bias=False),\n",
    "            nn.ReLU(True),\n",
    "            # third layer\n",
    "            nn.ConvTranspose2d(256,128,4,stride=2,padding=1,bias=False),\n",
    "            nn.ReLU(True),\n",
    "            # fourth layer,\n",
    "            nn.ConvTranspose2d(128,64,4,stride=2,padding=1,bias=False),\n",
    "            nn.ReLU(True),\n",
    "            # Final layer\n",
    "            nn.ConvTranspose2d(64,1,4,stride=2,padding=1,bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self,input):\n",
    "        return self.main(input)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (main): Sequential(\n",
      "    (0): ConvTranspose2d(256, 512, kernel_size=(3, 4), stride=(1, 1), bias=False)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (9): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "netG = Generator(ngpu).to(device)\n",
    "\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    netG = nn.DataParallel(netG,list(range(ngpu)))\n",
    "\n",
    "netG.apply(weights_init)\n",
    "\n",
    "print(netG)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu,\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(1,1,(4,3),stride=(2,1),padding=1,bias=False),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(1,1,(4,3),stride=(2,1),padding=1,bias=False),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(1,1,(16,48),stride=1,padding=0,bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d(1, 1, kernel_size=(4, 3), stride=(2, 1), padding=(1, 1), bias=False)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(1, 1, kernel_size=(4, 3), stride=(2, 1), padding=(1, 1), bias=False)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Conv2d(1, 1, kernel_size=(16, 48), stride=(1, 1), bias=False)\n",
      "    (5): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "netD = Discriminator(ngpu).to(device)\n",
    "\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    netD = nn.DataParallel(netD,list(range(ngpu)))\n",
    "\n",
    "netD.apply(weights_init)\n",
    "\n",
    "print(netD)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "fixed_noise = torch.randn(1,256,1,1,device=device)\n",
    "\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "optimizerD = optim.Adam(netD.parameters(), lr = lr, betas = (beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr = lr, betas = (beta1, 0.999))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# train process\n",
    "\n",
    "# save losses to check training state\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "\n",
    "# iterate epoch\n",
    "for epoch in range(num_epochs):\n",
    "    # iterate batch in an epoch\n",
    "    for i ,data in enumerate(dataloader,0):\n",
    "        ####################\n",
    "        # (1) update discriminator network : maximize log(D(x)) + log(1 - D(G(z))))\n",
    "        ####################\n",
    "        # @@train real data@@\n",
    "        netD.zero_grad()\n",
    "        # Adapt to the size of the batches or the device to be used\n",
    "        real_cpu = data[0].to(device)\n",
    "        b_size = real_cpu.size(0)\n",
    "        label = torch.full((b_size,), real_label,\n",
    "                           dtype=torch.float, device= device)\n",
    "        # pass batch composed real data to D\n",
    "        output = netD(real_cpu).view(-1)\n",
    "        # get losses\n",
    "        errD_real = criterion(output,label)\n",
    "        # calculate degree of change while doing backpropagation\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        # @@ train fake data @@\n",
    "        # Generate latent space vector used in Generator\n",
    "        noise = torch.randn(b_size,256,1,1,device=device)\n",
    "        # Generate fake image using G\n",
    "        fake = netG(noise)\n",
    "        label.fill_(fake_label)\n",
    "        # Discriminate truth of data using D\n",
    "        output = netD(fake.detatch()).view(-1)\n",
    "        # Calculate losses of D\n",
    "        errD_fake = criterion(output,label)\n",
    "        # Calculate changes through backpropagation and accumulate changes which get before\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        # add losses which get from both fake image and real image\n",
    "        # At this time, errD is not used in backpropagation, but is used when reporting the learning state afterwards.\n",
    "        errD = errD_fake +errD_real\n",
    "\n",
    "        # Update D\n",
    "        optimizerD.step()\n",
    "\n",
    "        ###################\n",
    "        # (2) Update G network : maximize log(D(G(z)))\n",
    "        ###################\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label) # we use real label to get losses of Generator\n",
    "        # Pass fake data to D again because we update D just now\n",
    "        # At this time, G didn't update, but we get different value because D update\n",
    "        output = netD(fake).view(-1)\n",
    "        # get losses of G\n",
    "        errG = criterion(output,label)\n",
    "        # Calculate changes of G\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        # Update G\n",
    "        optimizerG.step()\n",
    "\n",
    "        # print training state\n",
    "        if i % 50 == 0:\n",
    "             print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                  % (epoch, num_epochs, i, len(dataloader),\n",
    "                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "\n",
    "        # save losses to draw graph later\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "\n",
    "        # save return value of G passed fixed noise\n",
    "        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n",
    "            with torch.no_grad():\n",
    "                fake = netG(fixed_noise).detach().cpu()\n",
    "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "\n",
    "        iters += 1\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}